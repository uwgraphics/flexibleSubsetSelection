{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third party\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib_inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "from scipy.spatial.distance import cdist\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Local\n",
    "import flexibleSubsetSelection as fss\n",
    "\n",
    "# Initialize notebook settings\n",
    "sns.set_theme() # set seaborn theme\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg') # vector plots\n",
    "%matplotlib inline \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleSize = 16\n",
    "labelSize = 14\n",
    "\n",
    "# Load datasets from csv\n",
    "socialMedia = pd.read_csv(\"../data/exampleDatasets/congressSocialMedia.csv\")\n",
    "ideology = pd.read_csv(\"../data/exampleDatasets/houseOnly116.csv\")\n",
    "photos = pd.read_csv(\"../data/exampleDatasets/congressPhotos.csv\")\n",
    "\n",
    "# Merge Twitter and Facebook follower counts\n",
    "socialMedia.rename(columns={'Bioguide ID': 'bioguide'}, inplace=True)\n",
    "socialMedia.rename(columns={'Max Total Followers': 'followers'}, inplace=True)\n",
    "socialMedia = socialMedia.pivot_table(index=[\"bioguide\"], \n",
    "                                      columns='Platform', \n",
    "                                      values='followers')\n",
    "\n",
    "socialMedia = socialMedia.reset_index().fillna(0)\n",
    "socialMedia['followers'] = socialMedia['facebook'] + socialMedia['twitter']\n",
    "socialMedia = socialMedia.drop(columns=['facebook', 'twitter'])\n",
    "\n",
    "# merge datasets\n",
    "ideology.rename(columns={'bioguide_id': 'bioguide'}, inplace=True)\n",
    "df = pd.merge(ideology, socialMedia, on='bioguide', how='inner')\n",
    "df = pd.merge(df, photos, on='icpsr', how='inner')\n",
    "\n",
    "# drop extra columns\n",
    "dropCols = [\"congress_x\", \"chamber_x\", \"state_icpsr\", \"last_means\",\n",
    "            \"district_code\", \"state\", \"party_code\", \"occupancy\", \n",
    "            \"bioname\", \"born_x\", \"died_x\", \"conditional\",\n",
    "            \"nominate_log_likelihood\", \"nominate_geo_mean_probability\", \n",
    "            \"nominate_number_of_votes\", \"nominate_number_of_errors\", \"source\", \n",
    "            \"provenance\", \"congress_y\", \"chamber_y\",  \"born_y\",  \"died_y\"]\n",
    "df.drop(inplace=True, columns=dropCols)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df[\"name\"] = df[\"name\"].str.split(\", \")\n",
    "df[\"name\"] = df[\"name\"].apply(lambda x: \" \".join(reversed(x)).title())\n",
    "\n",
    "party_mapping = {\n",
    "    \"Democratic Party\": \"Democrat\",\n",
    "    \"Republican Party\": \"Republican\"\n",
    "}\n",
    "df[\"party\"] = df[\"party\"].map(party_mapping)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = df, \n",
    "        x = \"nominate_dim1\", \n",
    "        y = \"nominate_dim2\",\n",
    "        alpha = 0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = df, \n",
    "        x = \"nokken_poole_dim1\", \n",
    "        y = \"nokken_poole_dim2\",\n",
    "        alpha = 0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['nominate_dim1', 'nominate_dim2', \"nokken_poole_dim1\", \"nokken_poole_dim2\"]\n",
    "cluster_range = range(5, 21)\n",
    "\n",
    "silhouette_scores = []\n",
    "cluster_labels = []\n",
    "kmeans_models = []\n",
    "\n",
    "# Loop through each cluster count\n",
    "for n_clusters in cluster_range:\n",
    "    # Apply KMeans with current cluster count\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans.fit(df[features])\n",
    "    \n",
    "    # Get cluster labels and compute silhouette score\n",
    "    labels = kmeans.labels_\n",
    "    silhouette_avg = silhouette_score(df[features], labels)\n",
    "    \n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "    cluster_labels.append(labels)\n",
    "    kmeans_models.append(kmeans)\n",
    "\n",
    "# Find the optimal number of clusters\n",
    "optimal_index = np.argmax(silhouette_scores)\n",
    "optimal_cluster_count = cluster_range[optimal_index]\n",
    "optimal_cluster_labels = cluster_labels[optimal_index]\n",
    "optimal_kmeans_model = kmeans_models[optimal_index]\n",
    "\n",
    "# Assign the optimal cluster labels to the dataframe\n",
    "df[\"cluster\"] = optimal_cluster_labels\n",
    "\n",
    "# Calculate distances to the cluster centers and add to the dataframe\n",
    "df['centerDist'] = np.min(cdist(df[features], optimal_kmeans_model.cluster_centers_), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fss.Dataset(data=df, features=[\"followers\", \"centerDist\"])\n",
    "\n",
    "objectives = [fss.objective.clusterCenters, fss.metric.max]\n",
    "parameters = {}\n",
    "weights = [1, 1]\n",
    "lossFunction = fss.MultiCriterion(objectives, parameters, weights)\n",
    "solver = fss.Solver(algorithm=fss.algorithm.greedySwap, loss=lossFunction)\n",
    "\n",
    "subset = solver.solve(dataset, s=optimal_cluster_count)\n",
    "print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_to_circle(image, zoom):\n",
    "    width, height = image.size\n",
    "    square_size = min(width, height)\n",
    "    zoomed_square_size = int(square_size / zoom)\n",
    "    \n",
    "    # Calculate the new cropping box, centered horizontally and from the top\n",
    "    left = (width - zoomed_square_size) // 2\n",
    "    upper = 20\n",
    "    right = left + zoomed_square_size\n",
    "    lower = upper + zoomed_square_size\n",
    "    \n",
    "    # Crop to the new zoomed square\n",
    "    zoomed_square_image = image.crop((left, upper, right, lower))\n",
    "    \n",
    "    # Create circular mask\n",
    "    mask = Image.new('L', (zoomed_square_size, zoomed_square_size), 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "    draw.ellipse((0, 0, zoomed_square_size, zoomed_square_size), fill=255)\n",
    "    \n",
    "    # Apply circular mask to the image\n",
    "    circular_image = Image.new('RGBA', (zoomed_square_size, zoomed_square_size))\n",
    "    circular_image.paste(zoomed_square_image, (0, 0), mask=mask)\n",
    "    return circular_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "x=\"nominate_dim1\"\n",
    "y=\"nominate_dim2\"\n",
    "scale = 0.09\n",
    "zoom = 1.4\n",
    "palette = [color[\"green\"], color[\"yellow\"], color[\"orange\"], color[\"blue\"], color[\"darkGreen\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10.5, 7))  # Adjust the figure size as needed\n",
    "grid = GridSpec(nrows=2, ncols=3, figure=fig)\n",
    "ax1 = fig.add_subplot(grid[:, 0:2])\n",
    "ax2 = fig.add_subplot(grid[1:, 2:])\n",
    "\n",
    "sns.scatterplot(data=df, \n",
    "                x=x, \n",
    "                y=y, \n",
    "                hue = \"cluster\", \n",
    "                palette  =palette, \n",
    "                size = \"followers\",\n",
    "                sizes = (50, 2000),\n",
    "                alpha = 0.6,\n",
    "                ax=ax1)\n",
    "\n",
    "sns.scatterplot(data = subset.df,\n",
    "                x = x, \n",
    "                y = y, \n",
    "                hue = \"cluster\", \n",
    "                palette = palette,\n",
    "                s = 2000,\n",
    "                edgecolor = None,\n",
    "                ax=ax1)\n",
    "\n",
    "for index, row in subset.df.iterrows(): \n",
    "    image_path = row['image']\n",
    "    image = Image.open(\"datasets/\" + image_path)\n",
    "    circular_image = np.array(crop_to_circle(image, zoom))\n",
    "\n",
    "    x = row['nominate_dim1']\n",
    "    y = row['nominate_dim2']\n",
    "    ax1.imshow(circular_image, \n",
    "               extent=(x - scale, x + scale, y - scale, y + scale), \n",
    "               alpha=1,\n",
    "               zorder=1)\n",
    "\n",
    "ax1.set_title('Ideology in the 116th Congress', fontsize=titleSize)\n",
    "ax1.set_xlabel('\\nEconomic/Redistributive', fontsize=labelSize)\n",
    "ax1.set_ylabel('Social/Racial\\n', fontsize=labelSize)\n",
    "ax1.set_xlim([-1.1, 1.1])\n",
    "ax1.set_ylim([-1.1, 1.1])\n",
    "ax1.get_legend().remove()\n",
    "\n",
    "sort = subset.df.sort_values(by=\"cluster\")\n",
    "labels = [f\"Rep. {name} ({party[0]}), {state}\" for name, party, state in zip(sort[\"name\"], sort[\"party\"], sort[\"state_abbrev\"])]\n",
    "\n",
    "legend_markers = [\n",
    "    mpatches.Circle((0.1, 0.1), 0.1, color=palette[i]) for i in range(len(subset.df[\"cluster\"]))\n",
    "]\n",
    "\n",
    "# Create a separate axis for the legend\n",
    "legend_ax = fig.add_axes([0.8, 0.6, 0.1, 0.4])\n",
    "legend_ax.axis('off')\n",
    "legend_ax.legend(handles=legend_markers, \n",
    "                 labels=labels, \n",
    "                 title='Cluster Representatives', \n",
    "                 loc='center')\n",
    "\n",
    "ax1.text(-0.75, -1.25, \"Liberal\", ha=\"center\", )\n",
    "ax1.text(0.75, -1.25, \"Conservative\", ha=\"center\")\n",
    "\n",
    "ax1.text(-1.35, -0.75, \"Liberal\", va=\"center\", rotation=90)\n",
    "ax1.text(-1.35, 0.75, \"Conservative\", va=\"center\", rotation=90)\n",
    "\n",
    "pareto_front_data = []\n",
    "for i, cluster_label in enumerate(subset.df[\"cluster\"]):\n",
    "    # Filter data for the current cluster\n",
    "    cluster_mask = dataset.df[\"cluster\"] == cluster_label\n",
    "    cluster_centerDist = dataset.df[\"centerDist\"][cluster_mask]\n",
    "    cluster_followers = dataset.df[\"followers\"][cluster_mask]\n",
    "\n",
    "    # Sort data by increasing 'centerDist'\n",
    "    sorted_indices = np.argsort(cluster_centerDist)\n",
    "    sorted_centerDist = cluster_centerDist.iloc[sorted_indices]\n",
    "    sorted_followers = cluster_followers.iloc[sorted_indices]\n",
    "\n",
    "    # Initialize variables for Pareto front\n",
    "    pareto_front_centerDist = [sorted_centerDist.iloc[0]]\n",
    "    pareto_front_followers = [sorted_followers.iloc[0]]\n",
    "\n",
    "    # Iterate through the sorted data to find Pareto front\n",
    "    for j in range(1, len(sorted_centerDist)):\n",
    "        if sorted_followers.iloc[j] > pareto_front_followers[-1]:\n",
    "            pareto_front_centerDist.append(sorted_centerDist.iloc[j])\n",
    "            pareto_front_followers.append(sorted_followers.iloc[j])\n",
    "\n",
    "    # Plot the Pareto front for the current cluster\n",
    "    ax2.plot(pareto_front_centerDist, \n",
    "             pareto_front_followers, \n",
    "             color=palette[cluster_label],\n",
    "             lw=2)\n",
    "\n",
    "sns.scatterplot(data=dataset.df, \n",
    "                x=\"centerDist\", \n",
    "                y=\"followers\", \n",
    "                hue=\"cluster\",\n",
    "                ax=ax2,\n",
    "                palette=palette,\n",
    "                alpha=0.2)\n",
    "\n",
    "sns.scatterplot(data=subset.df, \n",
    "                x=\"centerDist\", \n",
    "                y=\"followers\", \n",
    "                hue=\"cluster\",\n",
    "                ax=ax2,\n",
    "                palette=palette,\n",
    "                s=80,\n",
    "                zorder=2)\n",
    "\n",
    "ax2.set_title('Pareto Front for Subset Selection', fontsize=labelSize)\n",
    "ax2.set_xlabel('Distance from Cluster Center')\n",
    "ax2.set_ylabel('Follower Count')\n",
    "ax2.get_legend().remove()\n",
    "\n",
    "plt.subplots_adjust()\n",
    "plt.savefig(\"congress.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in subset.df.iterrows():  # Use head() to limit to 5 rows for demonstration\n",
    "    # Get the image file path from the 'image' column\n",
    "    image_path = row['image']\n",
    "    \n",
    "    # Load and display the image using matplotlib\n",
    "    image = Image.open(\"datasets/\" + image_path)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"{row['name']}, {row['party']}\")\n",
    "    plt.axis('off')  # Turn off axis\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=dataset.df, x=\"centerDist\", y=\"followers\")\n",
    "sns.scatterplot(data=subset.df, x=\"centerDist\", y=\"followers\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
