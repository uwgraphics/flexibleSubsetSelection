{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third party\n",
    "import cv2\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Local\n",
    "import flexibleSubsetSelection as fss\n",
    "\n",
    "# Initialize notebook settings\n",
    "sns.set_theme() # set seaborn theme\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg') # vector plots\n",
    "%matplotlib inline \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '../data/exampleDatasets/dance.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check that video was opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Initialize the pre-trained ResNet50 model\n",
    "model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "frames = []\n",
    "frame_count = 0\n",
    "max_frames = 1000  # Adjust this to limit the number of frames for t-SNE\n",
    "\n",
    "# Read video frames\n",
    "while cap.isOpened() and frame_count < max_frames:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # Convert BGR to RGB\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame)\n",
    "        frame_count += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Preprocess frames for the neural network\n",
    "processed_frames = []\n",
    "for frame in frames:\n",
    "    img = cv2.resize(frame, (224, 224))  # Resize frame to fit the model's expected input size\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    processed_frames.append(img)\n",
    "\n",
    "# Stack frames into a single numpy array\n",
    "processed_frames = np.vstack(processed_frames)\n",
    "\n",
    "# Extract features using ResNet50\n",
    "features = model.predict(processed_frames)\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=1, random_state=0)\n",
    "tsne_results = tsne.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tsne_results, columns=['Values'])\n",
    "df['Frame'] = df.index\n",
    "\n",
    "dataset = fss.Dataset(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = df.sample(frac=.02, random_state=1).sort_index()\n",
    "print(subset_df.shape)\n",
    "\n",
    "plt.plot(df['Frame'], df['Values'], label='Original Path')\n",
    "plt.plot(subset_df['Frame'], subset_df['Values'], 'ro--', label='Subset Path')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "plt.title('Comparison of Paths')\n",
    "plt.show()\n",
    "\n",
    "original_sequence = df['Values'].tolist()\n",
    "subset_sequence = subset_df['Values'].tolist()\n",
    "\n",
    "distance, path = fastdtw(original_sequence, subset_sequence)\n",
    "\n",
    "print(\"DTW distance between paths:\", distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 20\n",
    "\n",
    "z, timeTotal, loss = approximation.greedySwap(dataset, s=s, objective=objectives.dtw)\n",
    "subset = sets.Subset(dataset, z, length=s)\n",
    "print(loss)\n",
    "\n",
    "with open('size={s}_obj=dtw_k=full.pkl', 'wb') as f:\n",
    "    pickle.dump(subset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastdtw import fastdtw\n",
    "\n",
    "# Original path\n",
    "original_path = [(0, 0), (1, 5), (2, 0)]\n",
    "\n",
    "# Subset path\n",
    "subset_path = [(0, 0), (1, 4), (2, 0)]\n",
    "\n",
    "# Calculate DTW distance\n",
    "distance, path = fastdtw(original_path, subset_path)\n",
    "\n",
    "print(\"DTW distance between paths:\", distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "scale = 0.07\n",
    "xshift = 20\n",
    "yshift = 40\n",
    "\n",
    "samples = 6\n",
    "sampled_indices = subset.df[\"Frame\"]\n",
    "sampled_frames = [frames[i] for i in sampled_indices]\n",
    "\n",
    "# Create a figure and an axis for the plot\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "# Plot t-SNE embedding\n",
    "ax.plot(range(len(tsne_results)), \n",
    "        tsne_results, \n",
    "        color=color[\"green\"], \n",
    "        lw=3) \n",
    "\n",
    "for j, (i, frame) in enumerate(zip(sampled_indices, sampled_frames)):\n",
    "    height, width, _ = frame.shape\n",
    "    crop_height = height  # Retain the full height\n",
    "    crop_width = int(height * 1.1)  # Retain the width proportionally\n",
    "    \n",
    "    # Ensure the cropped width does not exceed the original width\n",
    "    if crop_width > width:\n",
    "        crop_width = width\n",
    "    \n",
    "    # Calculate the left offset to crop equally from both sides\n",
    "    left_offset = (width - crop_width) // 2\n",
    "    \n",
    "    # Crop the image to a rectangle\n",
    "    cropped_image = frame[:, left_offset:left_offset + crop_width, :]  # Cropping to a rectangle\n",
    "    \n",
    "    if j == 7:  # Move every other image above\n",
    "        extent = (i - crop_width*scale - xshift + 5, \n",
    "                  i + crop_width*scale - xshift + 5, \n",
    "                  tsne_results[i] - crop_height*scale - yshift, \n",
    "                  tsne_results[i] + crop_height*scale - yshift)\n",
    "    elif j == 6:  # Move every other image above\n",
    "        extent = (i - crop_width*scale + xshift*2, \n",
    "                  i + crop_width*scale + xshift*2, \n",
    "                  tsne_results[i] - crop_height*scale + yshift + 25, \n",
    "                  tsne_results[i] + crop_height*scale + yshift + 25)\n",
    "    elif j==8:  # Move every other image above\n",
    "        extent = (i - crop_width*scale + xshift, \n",
    "                  i + crop_width*scale + xshift, \n",
    "                  tsne_results[i] - crop_height*scale + yshift, \n",
    "                  tsne_results[i] + crop_height*scale + yshift)\n",
    "    # elif j==11:  # Move every other image above\n",
    "    #     extent = (i - crop_width*scale + xshift, \n",
    "    #               i + crop_width*scale + xshift, \n",
    "    #               tsne_results[i] - crop_height*scale - yshift, \n",
    "    #               tsne_results[i] + crop_height*scale - yshift)\n",
    "    elif (j % 2 == 0 or j == 15) and j != 14:  # Move every other image above\n",
    "        extent = (i - crop_width*scale + xshift, \n",
    "                  i + crop_width*scale + xshift, \n",
    "                  tsne_results[i] - crop_height*scale + yshift, \n",
    "                  tsne_results[i] + crop_height*scale + yshift)\n",
    "    else:\n",
    "        extent = (i - crop_width*scale - xshift, \n",
    "                  i + crop_width*scale - xshift, \n",
    "                  tsne_results[i] - crop_height*scale - yshift, \n",
    "                  tsne_results[i] + crop_height*scale - yshift)\n",
    "    \n",
    "    ax.imshow(cropped_image, extent=extent, alpha=1, zorder=3)\n",
    "\n",
    "ax.set_title('t-SNE Video Embedding', fontsize=titleSize)\n",
    "ax.set_xlabel('Time', fontsize=labelSize)\n",
    "ax.set_ylabel('1D t-SNE Embedding', fontsize=labelSize)\n",
    "\n",
    "# Adjusting plot limits\n",
    "ax.set_xlim([0 - 50, len(frames) + 30])\n",
    "ax.set_ylim([tsne_results.min() - 50, tsne_results.max() + 55])\n",
    "\n",
    "sns.scatterplot(data=subset.df,\n",
    "                x=\"Frame\",\n",
    "                y=\"Values\",\n",
    "                color=color[\"orange\"],\n",
    "                s=100,  # Marker size\n",
    "                zorder=2,\n",
    "                ax=ax)\n",
    "\n",
    "# Create a line plot with a dotted line\n",
    "sns.lineplot(data=subset.df, \n",
    "             x=\"Frame\",\n",
    "             y=\"Values\",\n",
    "             color=color[\"orange\"],\n",
    "             linestyle=\"--\",\n",
    "             ax=ax)\n",
    "\n",
    "plt.savefig(\"motion.pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = 'datasets/dance.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check that video was opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Initialize the pre-trained ResNet50 model\n",
    "model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "frames = []\n",
    "frame_count = 0\n",
    "max_frames = 500  # Adjust this to limit the number of frames for t-SNE\n",
    "\n",
    "# Read video frames\n",
    "while cap.isOpened() and frame_count < max_frames:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # Convert BGR to RGB\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame)\n",
    "        frame_count += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Preprocess frames for the neural network\n",
    "processed_frames = []\n",
    "for frame in frames:\n",
    "    img = cv2.resize(frame, (224, 224))  # Resize frame to fit the model's expected input size\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    processed_frames.append(img)\n",
    "\n",
    "# Stack frames into a single numpy array\n",
    "processed_frames = np.vstack(processed_frames)\n",
    "\n",
    "# Extract features using ResNet50\n",
    "features = model.predict(processed_frames)\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "tsne_results = tsne.fit_transform(features)\n",
    "\n",
    "# Plot t-SNE embedding\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(tsne_results[:, 0], \n",
    "         tsne_results[:, 1], \n",
    "         color=color[\"green\"], \n",
    "         lw=3)\n",
    "\n",
    "plt.title('t-SNE Embedding of Video Frames with Sequential Connections')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
